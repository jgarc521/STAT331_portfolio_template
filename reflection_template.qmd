---
title: "STAT 331 Portfolio"
author: "Jose Garcia"
format: 
  html: 
    self-contained: true
layout: margin-left
editor: visual
execute: 
  eval: false
  echo: true
---

[**My Grade:**]{.underline} I believe my grade equivalent to course work evidenced below to be an B-.

[**Learning Objective Evidence:**]{.underline} In the code chunks below, provide code from a Lab or Challenge assignment where you believe you have demonstrated proficiency with the specified learning target. Be sure to specify **where** the code came from (e.g., Lab 4 Question 2).

## Working with Data

**WD-1: I can import data from a *variety* of formats (e.g., csv, xlsx, txt, etc.).**

-   `csv` Lab 5: Set Up

```{r wd-1-csv}

surveys <- read_csv(here::here("Week 5", "Lab 5", "surveys.csv"))
```

-   `xlsx` Practice Activity 4

```{r wd-1-xlsx}

military <- read_xlsx(here::here("data", 
                                 "gov_spending_per_capita.xlsx"), 
                      sheet = "Share of Govt. spending", 
                      skip = 6, 
                      n_max = 191)
```

-   `txt` Practice Activity 5.2

```{r wd-1-txt}

message <- read_csv(here::here("scrambled_message.txt")
                      )
```

**WD-2: I can select necessary columns from a dataset.**

```{r wd-2}

#Lab 4, p.5

metro_avg <- avocado_metro |>
  group_by(region) |>
  summarise(avg = mean(Total_Volume, na.rm = TRUE)) |> 
  select(region, avg) |>
  top_n(5)
```

**WD-3: I can filter rows from a dataframe for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   numeric

```{r wd-3-numeric}
#Lab 4, p.3

avocado_major |>
  filter(type == "organic" & year == 2017) |>
  group_by(region) |>
  summarise((tot_small = sum(Small_Avocado))) 
  
```

-   character -- specifically a string

```{r wd-3-string}

#Lab 4, p.3

avocado_major |>
  filter(type == "organic" & year == 2017) |>
  group_by(region) |>
  summarise((tot_small = sum(Small_Avocado))) 
```

-   factor

```{r wd-3-factor}
#Lab 4, p.3

avocado_major |>
  filter(type == "organic" & year == 2017) |>
  group_by(region) |>
  summarise((tot_small = sum(Small_Avocado))) 
  
```

-   date

```{r wd-3-date}
#PA 5.1, p.3

suspects <- suspects |>
  filter(pm(with_tz(time = Time.Spotted, tzone = "Iceland"))) == TRUE
```

**WD-4: I can modify existing variables and create new variables in a dataframe for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   numeric

```{r wd-4-numeric}
#Lab 4, p.7

conventional <- avocado_cali |>
  group_by(region, type) |>
  mutate(Small = sum(Small_Avocado)/sum(Small_Avocado, Large_Avocado, XL_Avocado),
         Large = sum(Large_Avocado)/sum(Small_Avocado, Large_Avocado, XL_Avocado),
         'Extra Large' = sum(XL_Avocado)/sum(Small_Avocado, Large_Avocado, XL_Avocado)) |>
  pivot_longer(cols = Small: 'Extra Large', names_to = "Avocado_Size", values_to = "Proportions")
```

-   character -- specifically a string

```{r wd-4-string}

```

-   factor

```{r wd-4-factor}
#Practice Activity 3

colleges_clean <- colleges_clean |> 
  mutate(
    CONTROL = factor(CONTROL),
    REGION = factor(REGION)
  )
```

-   date

```{r wd-4-date}
#PA 5.1, p.1

suspects <- suspects |>
  mutate(Time.Spotted = force_tz(time = Time.Spotted,
                                 tzone = "America/Los_Angeles")) |>
  filter(pm(Time.Spotted) == TRUE)
```

**WD-5: I can use mutating joins to combine multiple dataframes.**

-   `left_join()`

```{r wd-5-left}
#Lab 4, p.5

metro_plot <- left_join(x = metro_avg, y = avocado_metro)
```

-   `right_join()`

```{r wd-5-right}

```

-   `inner_join()`

```{r wd-5-inner}
#Preview Activity 4.3

inner_join(prof_info, prof_course)
```

-   `full_join()`

```{r wd-5-full}
#Preview Activity 4.3

full_join(prof_info, prof_course)
```

**WD-6: I can use filtering joins to filter rows from a dataframe.**

-   `semi_join()`

```{r wd-6-semi}
#Lab 4, p.2

avocado_metro <- avocado_clean |>
  semi_join(metro_regions, by = "region")
```

-   `anti_join()`

```{r wd-6-anti}
#Lab 4, p.2

avocado_major <- avocado_clean |>
  anti_join(metro_regions, by = "region") 
```

**WD-7: I can pivot dataframes from long to wide and visa versa**

-   `pivot_longer()`

```{r wd-7-long}
#Lab 4, p.7

conventional <- avocado_cali |>
  group_by(region, type) |>
  mutate(Small = sum(Small_Avocado)/sum(Small_Avocado, Large_Avocado, XL_Avocado),
         Large = sum(Large_Avocado)/sum(Small_Avocado, Large_Avocado, XL_Avocado),
         'Extra Large' = sum(XL_Avocado)/sum(Small_Avocado, Large_Avocado, XL_Avocado)) |>
  pivot_longer(cols = Small: 'Extra Large', names_to = "Avocado_Size", values_to = "Proportions")
```

-   `pivot_wider()`

```{r wd-7-wide}
#Lab 4, p.6

prices <- avocado_cali |>
  select(region, type, AveragePrice) |>
  group_by(region, type) |>
  summarise(avg = mean(AveragePrice)) |>
  pivot_wider(names_from = region, values_from = avg) |>
  summarise(diff = across(.cols = 'LosAngeles': 'SanFrancisco', .fns = diff))
```

## Reproducibility

**R-1: I can create professional looking, reproducible analyses using RStudio projects, Quarto documents, and the here package.**

I've done this in the following provided assignments:

**R-2: I can write well documented and tidy code.**

-   Example 1

```{r r-2-1}
#Lab 5, p. 2

surveys |>
  mutate(
    species = fct_reorder(species, weight)
  ) |>
  ggplot(aes(x = weight, y = species)) + 
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(color = "darkseagreen", alpha = 0.1) + 
  labs(x = "Weight (g)", y = "", title = "Species of Rodent ")

```

-   Example 2

```{r r-2-2}
#Lab 4, p.5

options(scipen = 999) #from Google, removes scientific notation

metro_avg <- avocado_metro |>
  group_by(region) |>
  summarise(avg = mean(Total_Volume, na.rm = TRUE)) |> 
  select(region, avg) |>
  top_n(5)

avocado_metro |>
  semi_join(metro_avg) |> #returns rows from x with a match in y
  ggplot(aes(x = region, y = Total_Volume, fill = region)) +
  geom_boxplot(position = "dodge") + 
  labs(x = "Region", y = "", title = "Total Volume of Avocados for Top 5 Metro Regions", fill = "Region")

```

**R-3: I can write robust programs that are resistant to changes in inputs.**

-   Example 1

```{r r-3-1}
#Using column names instead of column positions (Lab 4, p.5)

metro_avg <- avocado_metro |>
  group_by(region) |>
  summarise(avg = mean(Total_Volume, na.rm = TRUE)) |> 
  select(region, avg) |>
  top_n(5)
```

-   Example 2

```{r r-3-2}

rescale_01 <- function(x) {
  if (!is.numeric(x)) {
    stop("Input vector is not numeric.")
  }
  if (length(x) < 2) {
    stop("Length of vector is not greater than 1.")
  }
  range_x <- range(x, na.rm = TRUE)
  rescaled_x <- (x - range_x[1]) / (range_x[2] - range_x[1])
  return(rescaled_x)
}

```

## Data Visualization & Summarization

**DVS-1: I can create visualizations for a *variety* of variable types (e.g., numeric, character, factor, date)**

-   numeric variables

```{r dvs-1-num}
#Lab 4, p.7

conventional <- avocado_cali |>
  group_by(region, type) |>
  mutate(Small = sum(Small_Avocado)/sum(Small_Avocado, Large_Avocado, XL_Avocado),
         Large = sum(Large_Avocado)/sum(Small_Avocado, Large_Avocado, XL_Avocado),
         'Extra Large' = sum(XL_Avocado)/sum(Small_Avocado, Large_Avocado, XL_Avocado)) |>
  pivot_longer(cols = Small: 'Extra Large', names_to = "Avocado_Size", values_to = "Proportions")

conventional |>
  ggplot(aes(x = region, y = Proportions, fill = Avocado_Size)) + 
  geom_col(position = "fill") + 
  facet_wrap(~ type) +
  scale_x_discrete(guide = guide_axis(n.dodge = 2)) +
  labs(x = "Region", y = "Proportion of Mean Avocados Sold")

```

-   numeric variables and categorical variables

```{r dvs-2-num-cat}

#Lab 9, p.8

alxxn <- namesA |>
  filter(Sex == "M", Name %in% c("Allan", "Alan", "Allen")) |>
  group_by(Year, Name) |>
  summarise(Total_Count = sum(Count))

ggplot(alxxn, aes(x = Year, y = Total_Count, color = Name)) +
  geom_line() +
  labs(x = "Year", y = "", title = "Popularity of Allan/Alan/Allen Over Time")
```

-   categorical variables

```{r dvs-2-cat}
#Lab 5, p.3

surveys |>
  mutate(day_of_week = fct_collapse(factor(day_of_week), 
                                    "Weekday" = c("Mon", "Tue", "Wed", "Thu", "Fri"),
                                    "Weekend" = c("Sat", "Sun"))) |>
  drop_na(day_of_week) |>
  ggplot(aes(x = day_of_week)) + 
  geom_bar() + 
  labs(x = "Day Type", y = "", title = "Number of Rodents Captured by Day Type") 

```

-   dates

```{r dvs-2-date}
#Lab 5, p.2

surveys |>
  mutate(day_of_week = factor(day_of_week),
         fct_relevel(day_of_week, "Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun")) |>
  drop_na(day_of_week) |>
  ggplot(aes(x = day_of_week)) + 
           geom_bar() + 
           labs(x = "Day of Week", y = "", title = "Number of Rodents Captured Each Day of the Week")

```

**DVS-2: I use plot modifications to make my visualization clear to the reader.**

-   Example 1

```{r dvs-2-1}
#Lab 5, p.1
#Here I used alpha to make the boxplots easier to see, removed the outliers, and provided a nice title rather than having it on the y-axis.

surveys |>
  mutate(
    species = fct_reorder(species, weight)
  ) |>
  ggplot(aes(x = weight, y = species)) + 
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(color = "darkseagreen", alpha = 0.1) + 
  labs(x = "Weight (g)", y = "", title = "Species of Rodent ")
```

-   Example 2

```{r dvs-2-2}
#Lab 4, p.5
#Used scipen to make it easier to read the values for the y-axis and used fill to make the visualization more clear.

options(scipen = 999) #from Google, removes scientific notation

metro_avg <- avocado_metro |>
  group_by(region) |>
  summarise(avg = mean(Total_Volume, na.rm = TRUE)) |> 
  select(region, avg) |>
  top_n(5)

avocado_metro |>
  semi_join(metro_avg) |> #returns rows from x with a match in y
  ggplot(aes(x = region, y = Total_Volume, fill = region)) +
  geom_boxplot(position = "dodge") + 
  labs(x = "Region", y = "", title = "Total Volume of Avocados for Top 5 Metro Regions", fill = "Region")

```

**DVS-3: I show creativity in my visualizations**

-   Example 1

```{r dvs-3-1}

#Lab 4, p.5
#Used scipen to make it easier to read the values for the y-axis and used fill to make the visualization more clear.

options(scipen = 999) #from Google, removes scientific notation

metro_avg <- avocado_metro |>
  group_by(region) |>
  summarise(avg = mean(Total_Volume, na.rm = TRUE)) |> 
  select(region, avg) |>
  top_n(5)

avocado_metro |>
  semi_join(metro_avg) |> #returns rows from x with a match in y
  ggplot(aes(x = region, y = Total_Volume, fill = region)) +
  geom_boxplot(position = "dodge") + 
  labs(x = "Region", y = "", title = "Total Volume of Avocados for Top 5 Metro Regions", fill = "Region")

```

-   Example 2

```{r dvs-3-2}
#Lab 4, p.7
#Started to incorporate themes and unique colors.

ggplot(fish_year, aes(x = year, y = mean_cond)) +
  geom_line(color = "steelblue", size = 1.5) +
  geom_point(color = "steelblue", size = 2.5) +
  labs(x = "Year", y = "", title = "Mean Condition Index of Blackfoot River Fish by Year") + 
  theme_classic() +
  theme(panel.grid.major = element_line(color = "lightgray"))


```

**DVS-4: I can calculate numerical summaries of variables.**

-   Example 1

```{r dvs-4-1}
#Lab 4, p.3

avocado_major |>
  filter(type == "organic" & year == 2017) |>
  group_by(region) |>
  summarise((tot_small = sum(Small_Avocado))) 
  
```

-   Example 2

```{r dvs-4-2}
#Lab 3, p.11

hiphop_clean |>
  group_by(word) |>
  filter(age < 20) |>
  summarise(avg = mean(familiarity)) |>
  slice_max(avg)

hiphop_clean |>
  group_by(word) |>
  filter(age < 20) |>
  summarise(avg = mean(familiarity)) |>
  slice_min(avg)
```

**DVS-5: I can find summaries of variables across multiple groups.**

-   Example 1

```{r dvs-5-1}
#Lab 4, p.6

avocado_cali <- avocado_clean |>
  filter(region %in% 
           c("LosAngeles", "SanDiego", "Sacramento", "SanFrancisco")
         )

prices <- avocado_cali |>
  select(region, type, AveragePrice) |>
  group_by(region, type) |>
  summarise(avg = mean(AveragePrice)) |>
  pivot_wider(names_from = region, values_from = avg) |>
  summarise(diff = across(.cols = 'LosAngeles': 'SanFrancisco', .fns = diff))
```

-   Example 2

```{r dvs-5-2}
#Lab 4, p.5

metro_avg <- avocado_metro |>
  group_by(region) |>
  summarise(avg = mean(Total_Volume, na.rm = TRUE)) |> 
  select(region, avg) |>
  top_n(5)
```

**DVS-6: I can create tables which make my summaries clear to the reader.**

-   Example 1

```{r dvs-6-1}
#Lab 9, p.1

tableA <- namesA |>
  group_by(Name, State, Sex) |>
    filter(Name == 'Allison') |>
  summarize(Count = sum(Count, na.rm = TRUE), .groups = "drop") |>
  pivot_wider(names_from = Sex, values_from = Count, values_fill = 0)

```

-   Example 2

```{r dvs-6-2}
#Lab 9, p.9

allan <- namesA |>
  filter(Sex == "M", Year == 2000, Name %in% c("Allan", "Alan", "Allen"),
         State %in% c("PA", "CA")) |>
  group_by(State, Name) |>
  summarise(Total_Count = sum(Count), .groups = "drop") |>
  pivot_wider(names_from = Name, values_from = Total_Count, values_fill = 0)
```

**DVS-7: I show creativity in my tables.**

-   Example 1

```{r dvs-7-1}
#Challenge 9, Part 2

allan2 <- namesA |>
  filter(Sex == "M", Year == 2000, Name %in% c("Allan", "Alan", "Allen"),
         State %in% c("PA", "CA")) |>
  group_by(State, Name) |>
  summarise(Total_Count = sum(Count), .groups = "drop") |>
  pivot_wider(names_from = Name, values_from = Total_Count, values_fill = 0) |>
  mutate(Total = Allan + Allen + Alan,
         Allan = round(100 * Allan / Total, 2),
         Allen = round(100* Allen / Total, 2),
         Alan = round(100 * Alan / Total, 2))

allan2 |>
  knitr::kable(
    format = "html",
    col.names = c("State", 'Alan Pct', "Allan Pct", 'Alan Pct', "Total"),
    caption = "Total Percent of Babies with each Spelling of Allan in 2000, by State")|>
      kable_classic(html_font = "Arial") |>
  kable_styling(full_width = TRUE, bootstrap_options = "striped", font_size = 12) |>
  footnote(general = "Source: StateNames_A dataset") |>
  row_spec(0, bold = TRUE, color = "white", background = "#406b99")
```

-   Example 2

```{r dvs-7-2}

#Challenge 9, Part 1

allan <- namesA |>
  filter(Sex == "M", Year == 2000, Name %in% c("Allan", "Alan", "Allen"),
         State %in% c("PA", "CA")) |>
  group_by(State, Name) |>
  summarise(Total_Count = sum(Count), .groups = "drop") |>
  pivot_wider(names_from = Name, values_from = Total_Count, values_fill = 0)

allan |>
  knitr::kable(
    format = "html",
    col.names = c("State", "Allan", "Allen", "Alan"),
    caption = "Total Number of Babies with Each Spelling of Allan in 2000") |>
  kableExtra::kable_classic(html_font = "Arial")
```

## Program Efficiency

**PE-1: I can write concise code which does not repeat itself.**

-   using a single function call

```{r pe-1-one-call}
#Lab 7, 3.4

fish_rescaled <- fish |>
  mutate(length_rescaled = rescale_01(length))
```

-   `across()`

```{r pe-1-across}
#Lab 7, 2.1

fish |>
  summarize(across(
     .cols = trip:species, ~ sum(is.na(.x))
  ))
```

-   `map()` functions

```{r pe-1-map-1}
#Lab 8, Step 4

xmas2 <- xmas %>%
  mutate(Full.Phrase = pmap_chr(.l = list(
    Day, Day.in.Words, Gift.Item, Verb, Adjective, Location), 
                                .f = make_phrase)
         )
```

**PE-2: I can write functions to reduce repetition in my code.**

-   Example 1

```{r pe2-1}
#Lab 7, 3.1

rescale_01 <- function(x) {
  if (!is.numeric(x)) {
    stop("Input vector is not numeric.")
  }
  if (length(x) < 2) {
    stop("Length of vector is not greater than 1.")
  }
  range_x <- range(x, na.rm = TRUE)
  rescaled_x <- (x - range_x[1]) / (range_x[2] - range_x[1])
  return(rescaled_x)
}
```

-   Example 2

```{r pe2-2}
#Lab 7, 3.5

rescale_column <- function(df, var_names) {
  
  stopifnot(is.data.frame(df))
  
  df <- df |>
    mutate(across(
      {{var_names}}, ~ rescale_01(.x)
    ))
  
  df
  
}
```

**PE-3:I can use iteration to reduce repetition in my code.**

-   `across()`

```{r pe-3-across}
#Lab 7, 3.5

rescale_column <- function(df, var_names) {
  
  stopifnot(is.data.frame(df))
  
  df <- df |>
    mutate(across(
      {{var_names}}, ~ rescale_01(.x)
    ))
  
  df
  
}
```

-   `map()` functions (Provide 2 Examples)

```{r pe-3-map-1}
#Lab 8, Step 4

map_chr(.x = 1: 12,
        .f = ~ sing_day(xmas2, .x, Full.Phrase))
```

```{r pe-3-map-2}
#Practice Activity 9.2

my_weights <- map_dbl(.x = 1:1000, 
                      .f = ~ music_man(n_tromb = 76, n_cor = 110, n_reed = 1035)
                      )
```

**PE-4: I can use modern tools when carrying out my analysis.**

-   Example 1

```{r pe-4-1}
#Lab 5, p.5
#Efficiently using the pipe function

surveys |>
  mutate(day_of_week = fct_collapse(factor(day_of_week), 
                                    "Weekday" = c("Mon", "Tue", "Wed", "Thu", "Fri"),
                                    "Weekend" = c("Sat", "Sun"))) |>
  drop_na(day_of_week) |>
  ggplot(aes(x = day_of_week)) + 
  geom_bar() + 
  labs(x = "Day Type", y = "", title = "Number of Rodents Captured by Day Type") 


```

-   Example 2

```{r pe-4-2}
#Lab 5, p.2
#Functions are not superseded or deprecated

surveys |>
  mutate(
    species = fct_reorder(species, weight)
  ) |>
  ggplot(aes(x = weight, y = species)) + 
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(color = "darkseagreen", alpha = 0.1) + 
  labs(x = "Weight (g)", y = "", title = "Species of Rodent ")
```

## Data Simulation & Modeling

**DSM-1: I can simulate data from a *variety* of probability models.**

-   Example 1

```{r dsm-1-1}
#Practice Activity 9.2

set.seed(1957)

music_man <- function(n_tromb, n_cor, n_reed){
  
  trombones <- rnorm(n_tromb, mean = 4.6, sd = 0.8)
  cornets <- runif(n_cor, min = 1.5, max = 3.5)
  reeds <- rchisq(n_reed, df = 4)
  
  return(
    sum(trombones, cornets, reeds)
  )
  
}

my_weights <- map_dbl(.x = 1:1000, 
                      .f = ~ music_man(n_tromb = 76, n_cor = 110, n_reed = 1035)
                      ) 

```

-   Example 2

```{r dsm-1-2}
#Practice Activity 9.2, Warm-Up

set.seed(123)

tromb <- rnorm(100, mean = 4.6, sd = 0.8)
sum(tromb < 4)
```

**DSM-2: I can fit a linear regression and extract necessary summary measures.**

-   Example 1

```{r dsm-2-1}
#Preview Activity 9.1

my_model_2 <- penguins |>
  lm(bill_length_mm ~ bill_depth_mm*species, data = _)
summary(my_model_2)

my_model_2 |>
  broom::augment() |>
  ggplot(aes(x = .fitted, y = .resid)) + 
  geom_point() + 
  geom_smooth(method = "lm", formula = y ~ x, se = FALSE)
```

-   Example 2

```{r dsm-2-2}
#Lab 9, p.6

allison_lm <- lm(Total_Count ~ Year, data = allison_summary)
summary(allison_lm)

allison_lm |>
  broom::augment() |>
  ggplot(aes(y = .resid, x = .fitted)) + 
  geom_point() 
```

## Revising My Thinking

<!-- How did you revise your thinking throughout the course? How did you revise your thinking on the code examples you have provided in your portfolio? -->

<div>

After a lab or challenge is graded, I make sure to first look at the comments left by both the professor and my peers. Doing this allows me to fully understand any mistakes I made in the assignment. Then, I go back and make the necessary changes to my code. However, the most important aspect of revisions, in my opinion, is making sure you don't make the same mistakes in the future. As such, when working on new assignments, I make sure to look back on older assignments to avoid making the same mistakes. A good portion of the code examples provided in my portfolio are from assignments that were revised. For those that were, I included some text detailing the feedback provided which sparked the revision. In this portfolio, I only made revisions to code examples if they were small enough to not change the learning outcome, for instance, changing axis labels.

</div>

## Extending My Thinking

<!-- How did you extended your thinking throughout the course? How did you extend your thinking on the code examples you have provided in your portfolio? -->

<div>

Normally, as I work through my assignments, I have to do external research to complete my work. For instance, if there is a specific function I need but don't know the syntax, I can use the internet to find out what the function is and how to use it. Other times, I use what I learned from previous assignments to improve what I am currently working on. The best example of this is when plotting data. At first, my graphs were very simple. But, as I learned to modify them, they slowly got more intuitive and easier to read. In the context of the code examples provided in my portfolio, I was able to see my progression of learning R and was able to see how my current skills might've made my older code a lot better.

</div>

## Peer Support & Collaboration

<!-- Include an image of feedback you gave that you are proud of (either in a peer review or in Discord) -->
